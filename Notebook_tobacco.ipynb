{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tobacco Documents Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathieu VANDECASTEELE - MASTER SID 2018-2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Université de Rouen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joint à ce rapport : scripts Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from script import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce document a pour but de rapporter l'étude de la classification des types des différents documents émis lors des procès contre les industries du tabac aux États-Unis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan de l'étude :\n",
    "* Description statistique et analyse du jeu de données\n",
    "* Découpe / Préparation / Pré-Traitement des données\n",
    "* Apprentissages de classifieurs\n",
    "* Conclusion, dernières analyses et Pistes d'amélioration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Analyse des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premières statistiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'État américain a collecté plus de 14 millions de documents, ici nous disposons d'un échantillon de 3482 éléments précisemment. \n",
    "Nous devons établir un classifieur de documents, nous avons 10 types différents à différenciers : Email, Advertisement, Form, Letter, etc.\n",
    "Première constatation dans un premier temps : 3482 données ce n'est pas beaucoup, cela pourra plus tard poser des problèmes, surtout pour une classification multi-classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous disposons comme données d'un .csv avec l'image_path et le label associé pour chacune. Nous disposons également des textes de ces images obtenus par OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Premiers Import nécessaires et Import des données.\n",
    "import pandas as pd\n",
    "csv_path = 'data/Tobacco3482.csv'\n",
    "data = pd.read_csv(csv_path, sep = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vérifie avec .describe() si on a bien 3482 données et s'il ya bien 10 labels différents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3482</td>\n",
       "      <td>3482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3482</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Scientific/10073624.jpg</td>\n",
       "      <td>Memo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       img_path label\n",
       "count                      3482  3482\n",
       "unique                     3482    10\n",
       "top     Scientific/10073624.jpg  Memo\n",
       "freq                          1   620"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble y avoir 3482 éléments également contenus dans les dossiers de textes obtenus par OCR donc on a pas de problèmes de cohérences de nombres de données entre le .csv et ces dernières."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Répartition des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysons la répartition des données avec quelques statistiques descriptives. Tout d'abord piochons 10 données au hasard pour établir une première observation :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>Report/514120277.jpg</td>\n",
       "      <td>Report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>Email/2085542332c.jpg</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>Email/2085761260b.jpg</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>Resume/40005130-5131.jpg</td>\n",
       "      <td>Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>Email/2085134821a.jpg</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>Report/502339200+-9201.jpg</td>\n",
       "      <td>Report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>Email/527862259+-2259.jpg</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>Report/504330344_504330348.jpg</td>\n",
       "      <td>Report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>Memo/2024072051_2024072053.jpg</td>\n",
       "      <td>Memo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>Email/81887335.jpg</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            img_path   label\n",
       "3013            Report/514120277.jpg  Report\n",
       "614            Email/2085542332c.jpg   Email\n",
       "642            Email/2085761260b.jpg   Email\n",
       "3109        Resume/40005130-5131.jpg  Resume\n",
       "590            Email/2085134821a.jpg   Email\n",
       "2881      Report/502339200+-9201.jpg  Report\n",
       "722        Email/527862259+-2259.jpg   Email\n",
       "2909  Report/504330344_504330348.jpg  Report\n",
       "2011  Memo/2024072051_2024072053.jpg    Memo\n",
       "827               Email/81887335.jpg   Email"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble y avoir plus d'emails que d'autres types de documents dans notre jeu de données. On note aussi en relançant la commande que pas mal de lettres ou encore de memos sont présents. Avons-nous une sur-représentation d'une ou plusieurs classe(s) particulière(s) ?\n",
    "\n",
    "On peut tracer le diagramme bâtons du nombre de documents par type de documents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memo             620\n",
      "Email            599\n",
      "Letter           567\n",
      "Form             431\n",
      "Report           265\n",
      "Scientific       261\n",
      "Advertisement    230\n",
      "Note             201\n",
      "News             188\n",
      "Resume           120\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11bdcb9e8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "repartition_numbers = data['label'].value_counts()\n",
    "print(repartition_numbers)\n",
    "repartition_numbers.plot.bar(title = 'Répartition des documents par label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons bel et bien 4 classes supérieures en nombre de données aux autres mais nous ne pouvons pas vraiment parler de sur-représensation.\n",
    "Le nombre de données restant globalement faible, si les résultats après apprentissage automatique de classifieurs ne sont pas satisfaisants, il faudrait augmenter ce nombre : avec de l'augmentation de données par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistiques Textuelles sur les classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À partir des données OCR, **étudions le nombre de mots moyens par type de document :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dictionnary_word_average_number = count_average_number_of_words_per_class('data/Tobacco3482-OCR/')\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.bar(range(len(dictionnary_word_average_number)), list(dictionnary_word_average_number.values()), align='center')\n",
    "plt.xticks(range(len(dictionnary_word_average_number)), list(dictionnary_word_average_number.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pre-Processing et Découpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille de X : 3482\n",
      "taille de y : 3482\n",
      "Fabriqué 4 jeux de données depuis les données : X_train, X_val, X_test, X_trainval (X_train+X_val) \n",
      "taille de train : 2089\n",
      "taille de val : 696\n",
      "taille de trainval : 2785\n",
      "taille de test : 697\n"
     ]
    }
   ],
   "source": [
    "datasets = organize_and_split_data(csv_path)\n",
    "X_train = datasets[0]\n",
    "X_val = datasets[1]\n",
    "X_test = datasets[2]\n",
    "X_trainval = datasets[3]\n",
    "y_train = datasets[4]\n",
    "y_val = datasets[5]\n",
    "y_test = datasets[6]\n",
    "y_trainval = datasets[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tokenization et Entraînements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization...\n",
      "Terminé !\n",
      "\n",
      "Taille du vocabulaire :\n",
      "77566\n",
      "\n",
      "Nombre de sets retournés : 2\n",
      "TFIDF...\n",
      "Terminé !\n",
      "Nombre de sets retournés : 2\n"
     ]
    }
   ],
   "source": [
    "datasets_tokenized_idf = tokenizing_and_tfidf(X_trainval, X_test)\n",
    "X_trainval_tf = datasets_tokenized_idf[0]\n",
    "X_test_tf = datasets_tokenized_idf[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1er entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement...\n",
      "Terminé !\n",
      "\n",
      "Evaluation par Cross-Validation (5) avec alpha = 1.0 :\n",
      "0.4692737729575612\n",
      "\n",
      "Précision/Score sur les données de Test : \n",
      "0.5150645624103299\n",
      "\n",
      "Matrice de Confusion :\n",
      "[[  6   0   0   0   0   0   0   0   0   0]\n",
      " [  0 112   0   0   0   1   1   0   0   0]\n",
      " [  3   0  38   0   0   6   7   1   0   7]\n",
      " [ 13   9   7  94  11  28   4  15  21  23]\n",
      " [ 23  15  38  29 107   5  29  19   0  23]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      1.00      0.24         6\n",
      "           1       0.82      0.98      0.90       114\n",
      "           2       0.46      0.61      0.52        62\n",
      "           3       0.76      0.42      0.54       225\n",
      "           4       0.91      0.37      0.53       288\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.09      1.00      0.16         2\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       697\n",
      "   macro avg       0.32      0.44      0.29       697\n",
      "weighted avg       0.80      0.52      0.59       697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_MulNB = my_MultinomialNB(X_trainval_tf, X_test_tf, y_trainval, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation des Hyperparamètres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search MultinomialNB en cours...\n",
      "Pipeline à suivre : ['vector', 'tfidf', 'clf']\n",
      "Paramètres à tester:\n",
      "{'clf__alpha': (0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 0.7, 1.0),\n",
      " 'vector__max_df': (0.5, 0.7, 0.75, 0.8),\n",
      " 'vector__max_features': (1000, 1500, 2000)}\n",
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 288 out of 288 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminé !\n",
      "\n",
      "Meilleurs paramètres : \n",
      "\tclf__alpha: 0.2\n",
      "\tvector__max_df: 0.8\n",
      "\tvector__max_features: 1000\n",
      "\n",
      "Meilleur score: 0.713\n"
     ]
    }
   ],
   "source": [
    "Optimisation_MultNB = Grid_Search_CV_MultinomialNB(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement optimisé MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization...\n",
      "Terminé !\n",
      "\n",
      "Taille du vocabulaire :\n",
      "1000\n",
      "\n",
      "Nombre de sets retournés : 2\n",
      "TFIDF...\n",
      "Terminé !\n",
      "Nombre de sets retournés : 2\n"
     ]
    }
   ],
   "source": [
    "datasets_tokenized_idf = tokenizing_and_tfidf(X_trainval, X_test, 1000, 0.8)\n",
    "X_trainval_tf = datasets_tokenized_idf[0]\n",
    "X_test_tf = datasets_tokenized_idf[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement...\n",
      "Terminé !\n",
      "\n",
      "Evaluation par Cross-Validation (5) avec alpha = 0.2 :\n",
      "0.7134447272522897\n",
      "\n",
      "Précision/Score sur les données de Test : \n",
      "0.7130559540889526\n",
      "\n",
      "Matrice de Confusion :\n",
      "[[ 22   0   2   0   0   5   2   0   0   1]\n",
      " [  0 120   1   0   3   1   3   0   0   0]\n",
      " [  3   1  65   1   2   3   7   4   0   9]\n",
      " [  2   5   3  88  14   0   4   4   0   1]\n",
      " [  7   9   5  27  93   1  12   9   0   3]\n",
      " [  4   1   1   1   1  29   0   2   0   0]\n",
      " [  7   0   5   1   0   0  12   0   0   1]\n",
      " [  0   0   1   4   1   0   1  10   0   3]\n",
      " [  0   0   0   0   0   0   0   0  23   0]\n",
      " [  0   0   0   1   4   1   0   6   0  35]]\n",
      "\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.69      0.57        32\n",
      "           1       0.88      0.94      0.91       128\n",
      "           2       0.78      0.68      0.73        95\n",
      "           3       0.72      0.73      0.72       121\n",
      "           4       0.79      0.56      0.65       166\n",
      "           5       0.72      0.74      0.73        39\n",
      "           6       0.29      0.46      0.36        26\n",
      "           7       0.29      0.50      0.36        20\n",
      "           8       1.00      1.00      1.00        23\n",
      "           9       0.66      0.74      0.70        47\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       697\n",
      "   macro avg       0.66      0.70      0.67       697\n",
      "weighted avg       0.74      0.71      0.72       697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_MulNB = my_MultinomialNB(X_trainval_tf, X_test_tf, y_trainval, y_test,0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec Bag of Words simplement :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1er entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization...\n",
      "Terminé !\n",
      "\n",
      "Taille du vocabulaire :\n",
      "77566\n",
      "\n",
      "Nombre de sets retournés : 2\n"
     ]
    }
   ],
   "source": [
    "datasets_tokenized_bow = tokenizing(X_trainval, X_test)\n",
    "X_trainval_cv = datasets_tokenized_bow[0]\n",
    "X_test_cv = datasets_tokenized_bow[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement...\n",
      "Terminé !\n",
      "\n",
      "Evaluation par Cross-Validation (5) avec alpha = 1.0 :\n",
      "0.6384137848707525\n",
      "\n",
      "Précision/Score sur les données de Test : \n",
      "0.667144906743185\n",
      "\n",
      "Matrice de Confusion :\n",
      "[[ 11   0   1   0   0   1   0   0   0   0]\n",
      " [  0 106   0   0   0   0   1   0   0   0]\n",
      " [  8   0  57   0   0   4  15   1   0   8]\n",
      " [  6  18   4  98  17   0   6   9   0   2]\n",
      " [ 12  12  17  22 100   2  15  12   0  13]\n",
      " [  8   0   1   1   1  32   3   2   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0]\n",
      " [  0   0   1   1   0   0   0   7   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23   0]\n",
      " [  0   0   2   1   0   1   0   4   0  30]]\n",
      "\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.85      0.38        13\n",
      "           1       0.78      0.99      0.87       107\n",
      "           2       0.69      0.61      0.65        93\n",
      "           3       0.80      0.61      0.69       160\n",
      "           4       0.85      0.49      0.62       205\n",
      "           5       0.80      0.67      0.73        48\n",
      "           6       0.02      1.00      0.05         1\n",
      "           7       0.20      0.78      0.32         9\n",
      "           8       1.00      1.00      1.00        23\n",
      "           9       0.57      0.79      0.66        38\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       697\n",
      "   macro avg       0.59      0.78      0.60       697\n",
      "weighted avg       0.77      0.67      0.69       697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_MulNB_bow = my_MultinomialNB(X_trainval_cv, X_test_cv, y_trainval, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation des Hyperparamètres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search MultinomialNB en cours...\n",
      "Pipeline à suivre : ['vector', 'clf']\n",
      "Paramètres à tester:\n",
      "{'clf__alpha': (0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 0.7, 1.0),\n",
      " 'vector__max_df': (0.1, 0.2, 0.5, 0.7, 0.75, 0.8),\n",
      " 'vector__max_features': (500, 1000, 1500, 2000)}\n",
      "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 576 out of 576 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminé !\n",
      "\n",
      "Meilleurs paramètres : \n",
      "\tclf__alpha: 0.05\n",
      "\tvector__max_df: 0.75\n",
      "\tvector__max_features: 2000\n",
      "\n",
      "Meilleur score: 0.725\n"
     ]
    }
   ],
   "source": [
    "Optimisation_MultNB_bow = Grid_Search_CV_MultinomialNB(X_trainval, y_trainval,3,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement Final BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization...\n",
      "Terminé !\n",
      "\n",
      "Taille du vocabulaire :\n",
      "2000\n",
      "\n",
      "Nombre de sets retournés : 2\n"
     ]
    }
   ],
   "source": [
    "datasets_tokenized_bow = tokenizing(X_trainval, X_test,2000,0.75)\n",
    "X_trainval_cv = datasets_tokenized_bow[0]\n",
    "X_test_cv = datasets_tokenized_bow[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement...\n",
      "Terminé !\n",
      "\n",
      "Evaluation par Cross-Validation (5) avec alpha = 0.05 :\n",
      "0.7213508949131535\n",
      "\n",
      "Précision/Score sur les données de Test : \n",
      "0.7388809182209469\n",
      "\n",
      "Matrice de Confusion :\n",
      "[[ 24   0   3   0   0   5   4   0   0   1]\n",
      " [  0 127   0   0   3   0   3   0   0   0]\n",
      " [  3   0  65   2   2   2   4   0   0   8]\n",
      " [  1   4   3  95  13   0   4   3   0   1]\n",
      " [  7   4   4  18  90   1  10   7   0   8]\n",
      " [  3   1   1   2   2  29   0   3   0   1]\n",
      " [  7   0   6   1   1   2  15   1   0   1]\n",
      " [  0   0   0   4   4   0   1  17   0   3]\n",
      " [  0   0   0   0   0   0   0   0  23   0]\n",
      " [  0   0   1   1   3   1   0   4   0  30]]\n",
      "\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.65      0.59        37\n",
      "           1       0.93      0.95      0.94       133\n",
      "           2       0.78      0.76      0.77        86\n",
      "           3       0.77      0.77      0.77       124\n",
      "           4       0.76      0.60      0.67       149\n",
      "           5       0.72      0.69      0.71        42\n",
      "           6       0.37      0.44      0.40        34\n",
      "           7       0.49      0.59      0.53        29\n",
      "           8       1.00      1.00      1.00        23\n",
      "           9       0.57      0.75      0.65        40\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       697\n",
      "   macro avg       0.69      0.72      0.70       697\n",
      "weighted avg       0.75      0.74      0.74       697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_MulNB_bow = my_MultinomialNB(X_trainval_cv, X_test_cv, y_trainval, y_test, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning / MLP Classifier TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization...\n",
      "Terminé !\n",
      "\n",
      "Taille du vocabulaire :\n",
      "2000\n",
      "\n",
      "Nombre de sets retournés : 2\n",
      "TFIDF...\n",
      "Terminé !\n",
      "Nombre de sets retournés : 2\n"
     ]
    }
   ],
   "source": [
    "datasets_tokenized_idf = tokenizing_and_tfidf(X_trainval, X_test, 2000, 0.80)\n",
    "X_trainval_tf = datasets_tokenized_idf[0]\n",
    "X_test_tf = datasets_tokenized_idf[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.25689994\n",
      "Validation score: 0.354839\n",
      "Iteration 2, loss = 2.09381729\n",
      "Validation score: 0.480287\n",
      "Iteration 3, loss = 1.90010940\n",
      "Validation score: 0.544803\n",
      "Iteration 4, loss = 1.69537790\n",
      "Validation score: 0.609319\n",
      "Iteration 5, loss = 1.49011713\n",
      "Validation score: 0.645161\n",
      "Iteration 6, loss = 1.29547407\n",
      "Validation score: 0.684588\n",
      "Iteration 7, loss = 1.12509222\n",
      "Validation score: 0.716846\n",
      "Iteration 8, loss = 0.98290996\n",
      "Validation score: 0.727599\n",
      "Iteration 9, loss = 0.86478987\n",
      "Validation score: 0.759857\n",
      "Iteration 10, loss = 0.76713597\n",
      "Validation score: 0.781362\n",
      "Iteration 11, loss = 0.68622309\n",
      "Validation score: 0.795699\n",
      "Iteration 12, loss = 0.61797642\n",
      "Validation score: 0.795699\n",
      "Iteration 13, loss = 0.55865713\n",
      "Validation score: 0.795699\n",
      "Iteration 14, loss = 0.50691713\n",
      "Validation score: 0.795699\n",
      "Iteration 15, loss = 0.46251226\n",
      "Validation score: 0.813620\n",
      "Iteration 16, loss = 0.42153406\n",
      "Validation score: 0.802867\n",
      "Iteration 17, loss = 0.38569751\n",
      "Validation score: 0.817204\n",
      "Iteration 18, loss = 0.35366461\n",
      "Validation score: 0.817204\n",
      "Iteration 19, loss = 0.32425514\n",
      "Validation score: 0.810036\n",
      "Iteration 20, loss = 0.29837378\n",
      "Validation score: 0.813620\n",
      "Iteration 21, loss = 0.27447309\n",
      "Validation score: 0.810036\n",
      "Iteration 22, loss = 0.25331183\n",
      "Validation score: 0.813620\n",
      "Iteration 23, loss = 0.23403876\n",
      "Validation score: 0.810036\n",
      "Iteration 24, loss = 0.21641563\n",
      "Validation score: 0.817204\n",
      "Iteration 25, loss = 0.20041082\n",
      "Validation score: 0.817204\n",
      "Iteration 26, loss = 0.18606350\n",
      "Validation score: 0.824373\n",
      "Iteration 27, loss = 0.17298363\n",
      "Validation score: 0.817204\n",
      "Iteration 28, loss = 0.16126504\n",
      "Validation score: 0.820789\n",
      "Iteration 29, loss = 0.15057773\n",
      "Validation score: 0.824373\n",
      "Iteration 30, loss = 0.14030498\n",
      "Validation score: 0.817204\n",
      "Iteration 31, loss = 0.13133678\n",
      "Validation score: 0.824373\n",
      "Iteration 32, loss = 0.12329362\n",
      "Validation score: 0.820789\n",
      "Iteration 33, loss = 0.11576141\n",
      "Validation score: 0.810036\n",
      "Iteration 34, loss = 0.10881202\n",
      "Validation score: 0.820789\n",
      "Iteration 35, loss = 0.10259002\n",
      "Validation score: 0.817204\n",
      "Iteration 36, loss = 0.09686820\n",
      "Validation score: 0.817204\n",
      "Iteration 37, loss = 0.09180548\n",
      "Validation score: 0.817204\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "\n",
      "Précision/Score sur les données de Test : \n",
      "0.7776183644189383\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.78      0.65        32\n",
      "           1       0.92      0.96      0.94       130\n",
      "           2       0.89      0.76      0.82        98\n",
      "           3       0.82      0.75      0.79       134\n",
      "           4       0.78      0.73      0.75       126\n",
      "           5       0.75      0.73      0.74        41\n",
      "           6       0.56      0.53      0.55        43\n",
      "           7       0.37      0.59      0.46        22\n",
      "           8       1.00      1.00      1.00        23\n",
      "           9       0.68      0.75      0.71        48\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       697\n",
      "   macro avg       0.73      0.76      0.74       697\n",
      "weighted avg       0.79      0.78      0.78       697\n",
      "\n",
      "\n",
      "[[ 25   0   1   0   0   2   4   0   0   0]\n",
      " [  0 125   0   0   2   1   2   0   0   0]\n",
      " [  2   0  74   2   2   2   3   4   0   9]\n",
      " [  0   5   1 101  13   1   4   6   0   3]\n",
      " [  2   6   1  13  92   1   4   5   0   2]\n",
      " [  2   0   1   1   4  30   1   2   0   0]\n",
      " [ 13   0   4   1   0   0  23   1   0   1]\n",
      " [  1   0   1   3   1   1   0  13   0   2]\n",
      " [  0   0   0   0   0   0   0   0  23   0]\n",
      " [  0   0   0   2   4   2   0   4   0  36]]\n"
     ]
    }
   ],
   "source": [
    "first_mlp_tfidf = my_MLP(X_trainval_tf, X_test_tf, y_trainval, y_test, 0.0001, 'relu',100 ,True, True, 'auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation Hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search MLP en cours...\n",
      "Pipeline à suivre : ['mlp']\n",
      "Paramètres à tester:\n",
      "{'mlp__activation': ('relu', 'logistic'), 'mlp__batch_size': (50, 100)}\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminé !\n",
      "\n",
      "Meilleurs paramètres : \n",
      "\tmlp__activation: 'logistic'\n",
      "\tmlp__batch_size: 50\n",
      "\n",
      "Meilleur score: 0.761\n"
     ]
    }
   ],
   "source": [
    "Optimisation_MLP_tfidf = Grid_Search_CV_MLP(X_trainval_tf, y_trainval,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement Final DL - TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.17435452\n",
      "Validation score: 0.279570\n",
      "Iteration 2, loss = 2.08479468\n",
      "Validation score: 0.405018\n",
      "Iteration 3, loss = 2.00576309\n",
      "Validation score: 0.469534\n",
      "Iteration 4, loss = 1.91351482\n",
      "Validation score: 0.444444\n",
      "Iteration 5, loss = 1.80374910\n",
      "Validation score: 0.537634\n",
      "Iteration 6, loss = 1.67901232\n",
      "Validation score: 0.634409\n",
      "Iteration 7, loss = 1.55452296\n",
      "Validation score: 0.605735\n",
      "Iteration 8, loss = 1.42735403\n",
      "Validation score: 0.645161\n",
      "Iteration 9, loss = 1.30958427\n",
      "Validation score: 0.684588\n",
      "Iteration 10, loss = 1.19981167\n",
      "Validation score: 0.706093\n",
      "Iteration 11, loss = 1.10263250\n",
      "Validation score: 0.724014\n",
      "Iteration 12, loss = 1.01450640\n",
      "Validation score: 0.727599\n",
      "Iteration 13, loss = 0.93865186\n",
      "Validation score: 0.741935\n",
      "Iteration 14, loss = 0.86964208\n",
      "Validation score: 0.752688\n",
      "Iteration 15, loss = 0.80905079\n",
      "Validation score: 0.749104\n",
      "Iteration 16, loss = 0.75509574\n",
      "Validation score: 0.777778\n",
      "Iteration 17, loss = 0.70681450\n",
      "Validation score: 0.784946\n",
      "Iteration 18, loss = 0.66568579\n",
      "Validation score: 0.795699\n",
      "Iteration 19, loss = 0.62403325\n",
      "Validation score: 0.799283\n",
      "Iteration 20, loss = 0.58844255\n",
      "Validation score: 0.799283\n",
      "Iteration 21, loss = 0.55623822\n",
      "Validation score: 0.810036\n",
      "Iteration 22, loss = 0.52634960\n",
      "Validation score: 0.799283\n",
      "Iteration 23, loss = 0.49764241\n",
      "Validation score: 0.810036\n",
      "Iteration 24, loss = 0.47195974\n",
      "Validation score: 0.806452\n",
      "Iteration 25, loss = 0.44846946\n",
      "Validation score: 0.813620\n",
      "Iteration 26, loss = 0.42576773\n",
      "Validation score: 0.817204\n",
      "Iteration 27, loss = 0.40496997\n",
      "Validation score: 0.806452\n",
      "Iteration 28, loss = 0.38519369\n",
      "Validation score: 0.820789\n",
      "Iteration 29, loss = 0.36688680\n",
      "Validation score: 0.817204\n",
      "Iteration 30, loss = 0.34991816\n",
      "Validation score: 0.813620\n",
      "Iteration 31, loss = 0.33358772\n",
      "Validation score: 0.806452\n",
      "Iteration 32, loss = 0.31886544\n",
      "Validation score: 0.813620\n",
      "Iteration 33, loss = 0.30319979\n",
      "Validation score: 0.820789\n",
      "Iteration 34, loss = 0.29006715\n",
      "Validation score: 0.827957\n",
      "Iteration 35, loss = 0.27730740\n",
      "Validation score: 0.824373\n",
      "Iteration 36, loss = 0.26455967\n",
      "Validation score: 0.824373\n",
      "Iteration 37, loss = 0.25376391\n",
      "Validation score: 0.824373\n",
      "Iteration 38, loss = 0.24261141\n",
      "Validation score: 0.831541\n",
      "Iteration 39, loss = 0.23193207\n",
      "Validation score: 0.820789\n",
      "Iteration 40, loss = 0.22186062\n",
      "Validation score: 0.827957\n",
      "Iteration 41, loss = 0.21308087\n",
      "Validation score: 0.827957\n",
      "Iteration 42, loss = 0.20498268\n",
      "Validation score: 0.820789\n",
      "Iteration 43, loss = 0.19633174\n",
      "Validation score: 0.827957\n",
      "Iteration 44, loss = 0.18845166\n",
      "Validation score: 0.820789\n",
      "Iteration 45, loss = 0.18139537\n",
      "Validation score: 0.817204\n",
      "Iteration 46, loss = 0.17442217\n",
      "Validation score: 0.824373\n",
      "Iteration 47, loss = 0.16807457\n",
      "Validation score: 0.827957\n",
      "Iteration 48, loss = 0.16221668\n",
      "Validation score: 0.827957\n",
      "Iteration 49, loss = 0.15624671\n",
      "Validation score: 0.831541\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "\n",
      "Précision/Score sur les données de Test : \n",
      "0.7833572453371592\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.80      0.64        30\n",
      "           1       0.92      0.97      0.94       129\n",
      "           2       0.87      0.75      0.80        96\n",
      "           3       0.80      0.78      0.79       126\n",
      "           4       0.83      0.74      0.78       132\n",
      "           5       0.75      0.83      0.79        36\n",
      "           6       0.63      0.50      0.56        52\n",
      "           7       0.40      0.56      0.47        25\n",
      "           8       1.00      1.00      1.00        23\n",
      "           9       0.68      0.75      0.71        48\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       697\n",
      "   macro avg       0.74      0.77      0.75       697\n",
      "weighted avg       0.79      0.78      0.79       697\n",
      "\n",
      "\n",
      "[[ 24   0   1   0   0   2   3   0   0   0]\n",
      " [  0 125   0   0   2   0   2   0   0   0]\n",
      " [  2   0  72   2   2   2   3   4   0   9]\n",
      " [  1   5   0  98  10   1   4   6   0   1]\n",
      " [  1   6   2  15  98   1   3   4   0   2]\n",
      " [  2   0   1   1   1  30   0   1   0   0]\n",
      " [ 15   0   6   1   1   1  26   1   0   1]\n",
      " [  0   0   0   4   2   1   0  14   0   4]\n",
      " [  0   0   0   0   0   0   0   0  23   0]\n",
      " [  0   0   1   2   2   2   0   5   0  36]]\n"
     ]
    }
   ],
   "source": [
    "final_mlp_tfidf = my_MLP(X_trainval_tf, X_test_tf, y_trainval, y_test, 0.0001, 'logistic',100 ,True, True, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL - BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization...\n",
      "Terminé !\n",
      "\n",
      "Taille du vocabulaire :\n",
      "2000\n",
      "\n",
      "Nombre de sets retournés : 2\n"
     ]
    }
   ],
   "source": [
    "datasets_tokenized_bow = tokenizing(X_trainval, X_test,2000,0.75)\n",
    "X_trainval_cv = datasets_tokenized_bow[0]\n",
    "X_test_cv = datasets_tokenized_bow[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1er entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.92434087\n",
      "Validation score: 0.623656\n",
      "Iteration 2, loss = 1.15218400\n",
      "Validation score: 0.716846\n",
      "Iteration 3, loss = 0.77590377\n",
      "Validation score: 0.788530\n",
      "Iteration 4, loss = 0.56883509\n",
      "Validation score: 0.802867\n",
      "Iteration 5, loss = 0.44259638\n",
      "Validation score: 0.802867\n",
      "Iteration 6, loss = 0.35956519\n",
      "Validation score: 0.799283\n",
      "Iteration 7, loss = 0.29885061\n",
      "Validation score: 0.813620\n",
      "Iteration 8, loss = 0.25525829\n",
      "Validation score: 0.795699\n",
      "Iteration 9, loss = 0.22032924\n",
      "Validation score: 0.810036\n",
      "Iteration 10, loss = 0.19264041\n",
      "Validation score: 0.813620\n",
      "Iteration 11, loss = 0.17018337\n",
      "Validation score: 0.820789\n",
      "Iteration 12, loss = 0.15155542\n",
      "Validation score: 0.813620\n",
      "Iteration 13, loss = 0.13613187\n",
      "Validation score: 0.820789\n",
      "Iteration 14, loss = 0.12286913\n",
      "Validation score: 0.817204\n",
      "Iteration 15, loss = 0.11164829\n",
      "Validation score: 0.810036\n",
      "Iteration 16, loss = 0.10168763\n",
      "Validation score: 0.813620\n",
      "Iteration 17, loss = 0.09347695\n",
      "Validation score: 0.802867\n",
      "Iteration 18, loss = 0.08612329\n",
      "Validation score: 0.806452\n",
      "Iteration 19, loss = 0.07962069\n",
      "Validation score: 0.799283\n",
      "Iteration 20, loss = 0.07426076\n",
      "Validation score: 0.806452\n",
      "Iteration 21, loss = 0.06909662\n",
      "Validation score: 0.810036\n",
      "Iteration 22, loss = 0.06480842\n",
      "Validation score: 0.802867\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "\n",
      "Précision/Score sur les données de Test : \n",
      "0.7962697274031564\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.69      0.57        32\n",
      "           1       0.97      0.96      0.96       138\n",
      "           2       0.90      0.76      0.82        99\n",
      "           3       0.81      0.79      0.80       126\n",
      "           4       0.81      0.76      0.79       126\n",
      "           5       0.78      0.94      0.85        33\n",
      "           6       0.73      0.55      0.62        55\n",
      "           7       0.40      0.56      0.47        25\n",
      "           8       1.00      1.00      1.00        23\n",
      "           9       0.60      0.80      0.69        40\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       697\n",
      "   macro avg       0.75      0.78      0.76       697\n",
      "weighted avg       0.81      0.80      0.80       697\n",
      "\n",
      "\n",
      "[[ 22   2   2   1   0   3   1   0   0   1]\n",
      " [  0 132   1   0   2   1   2   0   0   0]\n",
      " [  2   0  75   2   2   2   2   4   0  10]\n",
      " [  0   1   0 100  12   0   2   7   0   4]\n",
      " [  1   1   2  14  96   1   3   6   0   2]\n",
      " [  1   0   0   0   0  31   0   1   0   0]\n",
      " [ 18   0   3   1   2   1  30   0   0   0]\n",
      " [  1   0   0   4   1   1   0  14   0   4]\n",
      " [  0   0   0   0   0   0   0   0  23   0]\n",
      " [  0   0   0   1   3   0   1   3   0  32]]\n"
     ]
    }
   ],
   "source": [
    "first_mlp_bow = my_MLP(X_trainval_cv, X_test_cv, y_trainval, y_test, 0.0001, 'relu',100 ,True, True, 'auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation Hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search MLP en cours...\n",
      "Pipeline à suivre : ['mlp']\n",
      "Paramètres à tester:\n",
      "{'mlp__activation': ('relu', 'tanh'), 'mlp__batch_size': (50, 150, 200)}\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  6.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminé !\n",
      "\n",
      "Meilleurs paramètres : \n",
      "\tmlp__activation: 'relu'\n",
      "\tmlp__batch_size: 200\n",
      "\n",
      "Meilleur score: 0.768\n"
     ]
    }
   ],
   "source": [
    "Optimisation_MLP_bow = Grid_Search_CV_MLP(X_trainval_cv, y_trainval,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement Final DL BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.92434087\n",
      "Validation score: 0.623656\n",
      "Iteration 2, loss = 1.15218400\n",
      "Validation score: 0.716846\n",
      "Iteration 3, loss = 0.77590377\n",
      "Validation score: 0.788530\n",
      "Iteration 4, loss = 0.56883509\n",
      "Validation score: 0.802867\n",
      "Iteration 5, loss = 0.44259638\n",
      "Validation score: 0.802867\n",
      "Iteration 6, loss = 0.35956519\n",
      "Validation score: 0.799283\n",
      "Iteration 7, loss = 0.29885061\n",
      "Validation score: 0.813620\n",
      "Iteration 8, loss = 0.25525829\n",
      "Validation score: 0.795699\n",
      "Iteration 9, loss = 0.22032924\n",
      "Validation score: 0.810036\n",
      "Iteration 10, loss = 0.19264041\n",
      "Validation score: 0.813620\n",
      "Iteration 11, loss = 0.17018337\n",
      "Validation score: 0.820789\n",
      "Iteration 12, loss = 0.15155542\n",
      "Validation score: 0.813620\n",
      "Iteration 13, loss = 0.13613187\n",
      "Validation score: 0.820789\n",
      "Iteration 14, loss = 0.12286913\n",
      "Validation score: 0.817204\n",
      "Iteration 15, loss = 0.11164829\n",
      "Validation score: 0.810036\n",
      "Iteration 16, loss = 0.10168763\n",
      "Validation score: 0.813620\n",
      "Iteration 17, loss = 0.09347695\n",
      "Validation score: 0.802867\n",
      "Iteration 18, loss = 0.08612329\n",
      "Validation score: 0.806452\n",
      "Iteration 19, loss = 0.07962069\n",
      "Validation score: 0.799283\n",
      "Iteration 20, loss = 0.07426076\n",
      "Validation score: 0.806452\n",
      "Iteration 21, loss = 0.06909662\n",
      "Validation score: 0.810036\n",
      "Iteration 22, loss = 0.06480842\n",
      "Validation score: 0.802867\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "\n",
      "Précision/Score sur les données de Test : \n",
      "0.7962697274031564\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.69      0.57        32\n",
      "           1       0.97      0.96      0.96       138\n",
      "           2       0.90      0.76      0.82        99\n",
      "           3       0.81      0.79      0.80       126\n",
      "           4       0.81      0.76      0.79       126\n",
      "           5       0.78      0.94      0.85        33\n",
      "           6       0.73      0.55      0.62        55\n",
      "           7       0.40      0.56      0.47        25\n",
      "           8       1.00      1.00      1.00        23\n",
      "           9       0.60      0.80      0.69        40\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       697\n",
      "   macro avg       0.75      0.78      0.76       697\n",
      "weighted avg       0.81      0.80      0.80       697\n",
      "\n",
      "\n",
      "[[ 22   2   2   1   0   3   1   0   0   1]\n",
      " [  0 132   1   0   2   1   2   0   0   0]\n",
      " [  2   0  75   2   2   2   2   4   0  10]\n",
      " [  0   1   0 100  12   0   2   7   0   4]\n",
      " [  1   1   2  14  96   1   3   6   0   2]\n",
      " [  1   0   0   0   0  31   0   1   0   0]\n",
      " [ 18   0   3   1   2   1  30   0   0   0]\n",
      " [  1   0   0   4   1   1   0  14   0   4]\n",
      " [  0   0   0   0   0   0   0   0  23   0]\n",
      " [  0   0   0   1   3   0   1   3   0  32]]\n"
     ]
    }
   ],
   "source": [
    "final_mlp_bow = my_MLP(X_trainval_cv, X_test_cv, y_trainval, y_test, 0.0001, 'relu',100 ,True, True, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour conclure, nous avons réalisé plusieurs classifiers et il semble que les méthodes utilisant le Deep Learning soient le plus efficaces. De même, on peut constater que parfois appliquer une TF-IDF ne permet pas de progresser dans la classification et qu'un simple modèle Bag of Words suffit.\n",
    "À retenir également aussi qu'il est important de choisir un nombre max de features lorsque l'on construit un vocabulaire, cela a une influence non-négligeable sur les résultats finaux.\n",
    "\n",
    "Ces résultats d'environ 80% sont satisfaisants mais nous pouvons aller plus loin :\n",
    "* Améliorer l'OCR pour une meilleur reconnaissance des mots et gagner en classification.\n",
    "* Augmenter le nombre de données disponibles, il n'y en a pas assez pour certaines classes qui sont parfois sous-représentées par rapport à d'autres.\n",
    "* Utiliser un autre modèle de représentation pour les textes comme des Embeddings.\n",
    "* Utiliser des réseaux de neurones plus complexes comme les LSTM, notamment avec le framework Keras.\n",
    "* Posséder un peu plus de puissance de calcul afin de tuner beaucoup plus d'hyper-paramètres."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
